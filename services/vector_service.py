from sentence_transformers import SentenceTransformer
import faiss, numpy as np, json
import os, pickle

INDEX_PATH = "vector_db/deposit.index"
META_PATH = "vector_db/deposit_meta.pkl"
EMB_MODEL = "intfloat/multilingual-e5-base"

_emb_model = None
_index = None
_docs = None

def _lazy_load():
    """í•„ìš”ì‹œ ë²¡í„° DB, ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
    global _emb_model, _index, _docs

    if _emb_model is None:
        _emb_model = SentenceTransformer(EMB_MODEL)
        print("ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    if _index is None:
        if not os.path.exists(INDEX_PATH):
            raise FileNotFoundError(f"âŒ {INDEX_PATH} not found.")
        _index = faiss.read_index(INDEX_PATH)
        print("ğŸ“¦ ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")

    if _docs is None:
        if os.path.exists(META_PATH):
            with open(META_PATH, "rb") as f:
                _docs = pickle.load(f)
            print(f"ğŸ“š {_docs and len(_docs)}ê°œ ë¬¸ì„œ ë©”íƒ€ ë¡œë“œë¨ (from deposit_meta.pkl)")
        else:
            print("âš ï¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì—†ìŒ. ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”")
            _docs = []

def search_similar_docs(query, top_k=3):
    """ì¿¼ë¦¬ì— ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ë°˜í™˜"""
    _lazy_load()
    query_emb = _emb_model.encode([query])
    D, I = _index.search(query_emb, top_k)

    results = []
    for idx, score in zip(I[0], D[0]):
        if 0 <= idx < len(_docs):
            results.append(_docs[idx])
            print(f"ğŸ“„ ë§¤ì¹­ ë¬¸ì„œ: {_docs[idx].get('meta', {})} | score={score:.4f}")

    return results


# return type: bool
def check_question_validity(question):
    results = search_similar_docs(question, top_k=1)
    return len(results) > 0