import pandas as pd
import json
import os
import re
import sys
import chardet  # ì¸ì½”ë”© ê°ì§€ë¥¼ ìœ„í•´ ì‚¬ìš© (pip install chardet)

# âœ… ì™¸ë¶€ì—ì„œ íŒŒì¼ ê²½ë¡œë¥¼ ì¸ìë¡œ ë°›ìŒ
if len(sys.argv) < 2:
    raise ValueError("âŒ CSV íŒŒì¼ ê²½ë¡œë¥¼ ì¸ìë¡œ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆ: python convert_csv_to_json_auto.py data/raw_data/ìƒˆíŒŒì¼.csv")

CSV_PATH = sys.argv[1]
JSON_PATH = "data/deposit_docs.json"

# ============================================
# 1ï¸âƒ£ CSV ì¸ì½”ë”© ë° í—¤ë” ìë™ ê°ì§€
# ============================================

def read_csv_auto(path):
    """CSV ì¸ì½”ë”© ë° í—¤ë” ìë™ ê°ì§€ í›„ DataFrameìœ¼ë¡œ ë¡œë“œ"""
    try:
        # ğŸ” ì¸ì½”ë”© ìë™ ê°ì§€
        with open(path, "rb") as f:
            encoding_info = chardet.detect(f.read(50000))
        encoding = encoding_info["encoding"] or "utf-8"

        # ì²« ì¤„ ë¯¸ë¦¬ ë³´ê¸°
        preview = pd.read_csv(path, nrows=1, header=None, encoding=encoding)
        first_row = preview.iloc[0].tolist()
        str_ratio = sum(isinstance(x, str) for x in first_row) / len(first_row)

        if str_ratio > 0.5:
            print(f"âœ… í—¤ë” ê°ì§€ë¨ â†’ ì²« í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì¸ì½”ë”©: {encoding})")
            df = pd.read_csv(path, header=0, encoding=encoding)
        else:
            print(f"âš ï¸ í—¤ë” ì—†ìŒ â†’ ì„ì˜ ì»¬ëŸ¼ëª… ë¶€ì—¬í•©ë‹ˆë‹¤. (ì¸ì½”ë”©: {encoding})")
            df = pd.read_csv(path, header=None, encoding=encoding)
            df.columns = [f"ì»¬ëŸ¼{i+1}" for i in range(len(df.columns))]
    except Exception as e:
        raise RuntimeError(f"CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
    return df.fillna("")

df = read_csv_auto(CSV_PATH)

# ============================================
# 2ï¸âƒ£ ì£¼ìš” ì»¬ëŸ¼ ìë™ íƒì§€ (ê¸ˆë¦¬ / ì€í–‰ëª… / ìƒí’ˆëª… / ê¸°ê°„)
# ============================================

def detect_column(columns, keywords):
    for col in columns:
        if any(kw in str(col) for kw in keywords):
            return col
    return None

col_bank = detect_column(df.columns, ["ê¸ˆìœµíšŒì‚¬", "ì€í–‰", "ê¸°ê´€"])
col_product = detect_column(df.columns, ["ìƒí’ˆ", "ì˜ˆê¸ˆ", "í€ë“œ", "ëŒ€ì¶œ"])
col_rate = detect_column(df.columns, ["ê¸ˆë¦¬", "ì´ìœ¨", "ìˆ˜ìµë¥ "])
col_period = detect_column(df.columns, ["ê¸°ê°„", "ë§Œê¸°", "ê°€ì…"])

# ============================================
# 3ï¸âƒ£ ê° í–‰(row)ì„ ë¬¸ì¥ í˜•íƒœë¡œ ë³€í™˜
# ============================================

records = []
for _, row in df.iterrows():
    text_parts = [f"{col}: {row[col]}" for col in df.columns]
    combined_text = " | ".join(text_parts)

    # ê¸ˆë¦¬ ìˆ«ì ë³€í™˜
    rate_val = None
    if col_rate and str(row[col_rate]).strip() != "":
        match = re.search(r"[\d.]+", str(row[col_rate]))
        rate_val = float(match.group()) if match else None

    meta = {
        "bank": str(row[col_bank]) if col_bank else None,
        "product": str(row[col_product]) if col_product else None,
        "rate": rate_val,
        "period": str(row[col_period]) if col_period else None,
    }

    records.append({
        "source": os.path.basename(CSV_PATH),
        "content": combined_text,
        "meta": {k: v for k, v in meta.items() if v not in [None, ""]},
    })

# ============================================
# 4ï¸âƒ£ ê¸°ì¡´ JSON ë³‘í•© ë° ì €ì¥
# ============================================

if os.path.exists(JSON_PATH):
    with open(JSON_PATH, "r", encoding="utf-8") as f:
        old_data = json.load(f)
else:
    old_data = []

source_name = os.path.basename(CSV_PATH)
filtered_old = [item for item in old_data if item["source"] != source_name]
new_data = filtered_old + records

os.makedirs(os.path.dirname(JSON_PATH), exist_ok=True)
with open(JSON_PATH, "w", encoding="utf-8") as f:
    json.dump(new_data, f, ensure_ascii=False, indent=2)

print(f"\nâœ… ì´ {len(records)}ê°œì˜ í–‰ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {JSON_PATH}")
if col_rate is None:
    print("âš ï¸ ê¸ˆë¦¬ ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. rate í•„ë“œëŠ” Noneìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
