import os, json, pickle
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss

# ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
DATA_PATH = os.path.join(BASE_DIR, "data", "deposit_docs.json")
VEC_DIR = os.path.join(BASE_DIR, "vector_db")
os.makedirs(VEC_DIR, exist_ok=True)

INDEX_PATH = os.path.join(VEC_DIR, "deposit.index")
META_PATH  = os.path.join(VEC_DIR, "deposit_meta.pkl")

# ì„ë² ë”© ëª¨ë¸
MODEL_NAME = "intfloat/multilingual-e5-base"

# í•œ ë²ˆì— ì„ë² ë”©í•  ë°°ì¹˜ í¬ê¸°
BATCH_SIZE = 100

def main():
    # ìƒˆ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    with open(DATA_PATH, "r", encoding="utf-8") as f:
        new_docs = json.load(f)

    # ëª¨ë¸ ë¡œë“œ
    model = SentenceTransformer(MODEL_NAME)

    # ê¸°ì¡´ ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ
    if os.path.exists(INDEX_PATH) and os.path.exists(META_PATH):
        print("ğŸ“¦ ê¸°ì¡´ ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ ì¤‘ ...")
        index = faiss.read_index(INDEX_PATH)
        with open(META_PATH, "rb") as f:
            old_meta = pickle.load(f)
    else:
        print("ğŸ†• ìƒˆ ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ...")
        index = None
        old_meta = []

    # ê¸°ì¡´ í…ìŠ¤íŠ¸ ì¤‘ë³µ ë°©ì§€
    existing_texts = set(d["content"] for d in old_meta)
    filtered_docs = [d for d in new_docs if d["content"] not in existing_texts]

    if not filtered_docs:
        print("âš ï¸ ì¶”ê°€í•  ìƒˆë¡œìš´ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    total = len(filtered_docs)
    print(f"â• {total}ê°œì˜ ìƒˆ ë¬¸ì„œ ì¶”ê°€ ì¤‘ ...")

    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„ë² ë”© ìƒì„± ë° ë¡œê·¸ ì¶œë ¥
    all_embs = []
    for i in range(0, total, BATCH_SIZE):
        batch_docs = filtered_docs[i:i + BATCH_SIZE]
        texts = [d["content"] for d in batch_docs]
        emb = model.encode(texts, normalize_embeddings=True).astype(np.float32)
        all_embs.append(emb)

        # âœ… 100ê°œ ë‹¨ìœ„ ë¡œê·¸ ì¶œë ¥
        print(f"[INFO] {min(i + BATCH_SIZE, total)}/{total} rows processed...")

    # ì „ì²´ ë³‘í•©
    all_embs = np.vstack(all_embs)
    dim = all_embs.shape[1]

    # ì¸ë±ìŠ¤ ì´ˆê¸°í™” ë˜ëŠ” ê¸°ì¡´ ì´ì–´ì“°ê¸°
    if index is None:
        index = faiss.IndexFlatIP(dim)
    index.add(all_embs)

    updated_meta = old_meta + filtered_docs

    # ì €ì¥
    faiss.write_index(index, INDEX_PATH)
    with open(META_PATH, "wb") as f:
        pickle.dump(updated_meta, f)

    print(f"âœ… ì¸ë±ì‹± ì™„ë£Œ (ì´ {len(updated_meta)}ê°œ ë¬¸ì„œ)")
    print(f"- index: {INDEX_PATH}")
    print(f"- meta : {META_PATH}")

if __name__ == "__main__":
    main()
